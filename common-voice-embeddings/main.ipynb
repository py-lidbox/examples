{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Automatically reload imported modules that are changed outside this notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# More pixels in figures\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.dpi\"] = 200\n",
    "\n",
    "# Init PRNG with fixed seed for reproducibility\n",
    "import numpy as np\n",
    "np_rng = np.random.default_rng(1)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(np_rng.integers(0, tf.int64.max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representation learning and back-end classification\n",
    "\n",
    "**2020-11-21**\n",
    "\n",
    "\n",
    "This example expands `common-voice-augmenting` by implementing language vector classification.\n",
    "So far, we have used the x-vector neural network as an end-to-end classifier, making classification decisions based on its log-softmax outputs.\n",
    "However, it can also be used for [representation learning](https://www.deeplearningbook.org/contents/representation.html) by adding a second step after training.\n",
    "Once we have found reasonably optimal weights for the network, we extract all speech data as fixed-length vectors and train a separate, back-end classifier on these vectors.\n",
    "These vectors are also called [embeddings](https://en.wikipedia.org/wiki/Embedding).\n",
    "As explained in the original [x-vector paper](\n",
    "http://danielpovey.com/files/2018_odyssey_xvector_lid.pdf), one benefit of this approach is that we could first train a single neural network on vast amounts of data in hundreds of languages, which can then be used as a feature extractor for producing training data to arbitrary back-end classifiers.\n",
    "These back-end classifiers could be trained on any subset of languages from the larger training set.\n",
    "\n",
    "\n",
    "## Data\n",
    "\n",
    "This example uses the same data as in the `common-voice-small` example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "\n",
    "languages = \"\"\"\n",
    "    et\n",
    "    mn\n",
    "    ta\n",
    "    tr\n",
    "\"\"\".split()\n",
    "\n",
    "languages = sorted(l.strip() for l in languages)\n",
    "\n",
    "display(Markdown(\"### Languages\"))\n",
    "display(Markdown('\\n'.join(\"* `{}`\".format(l) for l in languages)))\n",
    "\n",
    "bcp47_validator_url = 'https://schneegans.de/lv/?tags='\n",
    "display(Markdown(\"See [this tool]({}) for a description of the BCP-47 language codes.\"\n",
    "                 .format(bcp47_validator_url + urllib.parse.quote('\\n'.join(languages)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preparing the metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from lidbox.meta import (\n",
    "    common_voice,\n",
    "    generate_label2target,\n",
    "    verify_integrity,\n",
    "    read_audio_durations,\n",
    "    random_oversampling_on_split\n",
    ")\n",
    "\n",
    "\n",
    "workdir = \"/data/exp/cv4-embed\"\n",
    "datadir = \"/mnt/data/speech/common-voice/downloads/2020/cv-corpus\"\n",
    "\n",
    "print(\"work dir:\", workdir)\n",
    "print(\"data source dir:\", datadir)\n",
    "print()\n",
    "\n",
    "os.makedirs(workdir, exist_ok=True)\n",
    "assert os.path.isdir(datadir), datadir + \" does not exist\"\n",
    "\n",
    "dirs = sorted((f for f in os.scandir(datadir) if f.is_dir()), key=lambda f: f.name)\n",
    "\n",
    "print(datadir)\n",
    "for d in dirs:\n",
    "    if d.name in languages:\n",
    "        print(' ', d.name)\n",
    "        for f in os.scandir(d):\n",
    "            print('   ', f.name)\n",
    "\n",
    "missing_languages = set(languages) - set(d.name for d in dirs)\n",
    "assert missing_languages == set(), \"missing languages: {}\".format(missing_languages)\n",
    "\n",
    "meta = common_voice.load_all(datadir, languages)\n",
    "meta, lang2target = generate_label2target(meta)\n",
    "\n",
    "print(\"\\nsize of all metadata\", meta.shape)\n",
    "meta = meta.dropna()\n",
    "print(\"after dropping NaN rows\", meta.shape)\n",
    "\n",
    "print(\"verifying integrity\")\n",
    "verify_integrity(meta)\n",
    "print(\"ok\\n\")\n",
    "\n",
    "print(\"reading audio durations\")\n",
    "meta[\"duration\"] = read_audio_durations(meta)\n",
    "print(\"balancing the label distributions\")\n",
    "meta = random_oversampling_on_split(meta, \"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the feature extraction pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from lidbox.features import audio, cmvn\n",
    "import lidbox.data.steps as ds_steps\n",
    "import scipy.signal\n",
    "\n",
    "\n",
    "TF_AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "\n",
    "def metadata_to_dataset_input(meta):   \n",
    "    return {\n",
    "        \"id\": tf.constant(meta.index, tf.string),\n",
    "        \"path\": tf.constant(meta.path, tf.string),\n",
    "        \"label\": tf.constant(meta.label, tf.string),\n",
    "        \"target\": tf.constant(meta.target, tf.int32),\n",
    "        \"split\": tf.constant(meta.split, tf.string),\n",
    "        \"is_copy\": tf.constant(meta.is_copy, tf.bool),\n",
    "    }\n",
    "\n",
    "\n",
    "def read_mp3(x):\n",
    "    s, r = audio.read_mp3(x[\"path\"])\n",
    "    out_rate = 16000\n",
    "    s = audio.resample(s, r, out_rate)\n",
    "    s = audio.peak_normalize(s, dBFS=-3.0)\n",
    "    s = audio.remove_silence(s, out_rate)\n",
    "    return dict(x, signal=s, sample_rate=out_rate)\n",
    "\n",
    "\n",
    "def random_filter(x):\n",
    "    def scipy_filter(s, N=10):\n",
    "        b = np_rng.normal(0, 1, N)\n",
    "        return scipy.signal.lfilter(b, 1.0, s).astype(np.float32), b\n",
    "    s, _ = tf.numpy_function(\n",
    "        scipy_filter,\n",
    "        [x[\"signal\"]],\n",
    "        [tf.float32, tf.float64],\n",
    "        name=\"np_random_filter\")\n",
    "    s = tf.cast(s, tf.float32)\n",
    "    s = audio.peak_normalize(s, dBFS=-3.0)\n",
    "    return dict(x, signal=s)\n",
    "\n",
    "\n",
    "def random_speed_change(ds):\n",
    "    return ds_steps.random_signal_speed_change(ds, min=0.9, max=1.1, flag=\"is_copy\")\n",
    "\n",
    "\n",
    "def batch_extract_features(x):\n",
    "    with tf.device(\"GPU\"):\n",
    "        signals, rates = x[\"signal\"], x[\"sample_rate\"]\n",
    "        S = audio.spectrograms(signals, rates[0])\n",
    "        S = audio.linear_to_mel(S, rates[0])\n",
    "        S = tf.math.log(S + 1e-6)\n",
    "        S = cmvn(S, normalize_variance=False)\n",
    "    return dict(x, logmelspec=S)\n",
    "\n",
    "\n",
    "def pipeline_from_meta(data, split):\n",
    "    if split == \"train\":\n",
    "        data = data.sample(frac=1, random_state=np_rng.bit_generator)\n",
    "        \n",
    "    ds = (tf.data.Dataset\n",
    "            .from_tensor_slices(metadata_to_dataset_input(data))\n",
    "            .map(read_mp3, num_parallel_calls=TF_AUTOTUNE))\n",
    "    \n",
    "    if split == \"test\":\n",
    "        return (ds\n",
    "            .batch(1)\n",
    "            .map(batch_extract_features, num_parallel_calls=TF_AUTOTUNE)\n",
    "            .unbatch()\n",
    "            .cache(os.path.join(cachedir, \"data\", split))\n",
    "            .prefetch(1000))\n",
    "    else:\n",
    "        return (ds\n",
    "            .cache(os.path.join(cachedir, \"data\", split))\n",
    "            .prefetch(1000)\n",
    "            .apply(random_speed_change)\n",
    "            .map(random_filter, num_parallel_calls=TF_AUTOTUNE)\n",
    "            .batch(1)\n",
    "            .map(batch_extract_features, num_parallel_calls=TF_AUTOTUNE)\n",
    "            .unbatch())\n",
    "\n",
    "\n",
    "cachedir = os.path.join(workdir, \"cache\")\n",
    "os.makedirs(os.path.join(cachedir, \"data\"))\n",
    "\n",
    "split2ds = {split: pipeline_from_meta(meta[meta[\"split\"]==split], split)\n",
    "            for split in meta.split.unique()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling the caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split, ds in split2ds.items():\n",
    "    print(\"filling\", split, \"cache\")\n",
    "    _ = ds_steps.consume(ds, log_interval=2000) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a trained x-vector model\n",
    "\n",
    "We already have a trained instance of the x-vector model from `common-voice-augmenting` so we can skip training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lidbox.models import xvector\n",
    "\n",
    "\n",
    "previous_cachedir = \"/data/exp/cv4-augment/cache\"\n",
    "\n",
    "def load_trained_model(num_freq_bins=40, num_labels=len(lang2target)):\n",
    "    m = xvector.create(\n",
    "        input_shape=[None, num_freq_bins],\n",
    "        num_outputs=num_labels,\n",
    "        channel_dropout_rate=0.8)\n",
    "    m.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5))\n",
    "    _ = m.load_weights(os.path.join(previous_cachedir, \"model\", m.name))\n",
    "    return m\n",
    "\n",
    "\n",
    "model = load_trained_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating as an end-to-end classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lidbox.util import evaluate_testset_with_model\n",
    "from lidbox.visualize import draw_confusion_matrix\n",
    "\n",
    "\n",
    "def display_classification_report(report):\n",
    "    for m in (\"avg_detection_cost\", \"avg_equal_error_rate\", \"accuracy\"):\n",
    "        print(\"{}: {:.3f}\".format(m, report[m]))\n",
    "\n",
    "    lang_metrics = pd.DataFrame.from_dict(\n",
    "        {k: v for k, v in report.items() if k in lang2target})\n",
    "    lang_metrics[\"mean\"] = lang_metrics.mean(axis=1)\n",
    "    display(lang_metrics.T)\n",
    "\n",
    "    fig, ax = draw_confusion_matrix(report[\"confusion_matrix\"], lang2target)\n",
    "\n",
    "    \n",
    "report = evaluate_testset_with_model(\n",
    "    model=load_trained_model(),\n",
    "    test_ds=split2ds[\"test\"].map(lambda x: dict(x, input=x[\"logmelspec\"])).batch(1),\n",
    "    test_meta=meta[meta[\"split\"]==\"test\"],\n",
    "    lang2target=lang2target)\n",
    "\n",
    "display_classification_report(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the classifier as a feature extractor\n",
    "\n",
    "In previous examples we stopped here, but this time we'll make use of the internal representation our neural network has learned.\n",
    "As described in the [x-vector paper](\n",
    "http://danielpovey.com/files/2018_odyssey_xvector_lid.pdf), the language vectors should be extracted from the first fully connected layer, without activations.\n",
    "Lets create a new feature extractor model that uses same inputs as the trained x-vector model, but uses the `segment1` layer as its output layer.\n",
    "We also freeze the model by converting it into a `tf.function`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lidbox.util import model2function\n",
    "\n",
    "\n",
    "model = load_trained_model()\n",
    "xvec_layer = model.get_layer(name=\"segment1\")\n",
    "xvec_layer.activation = None\n",
    "xvec_extractor = model2function(\n",
    "    tf.keras.Model(inputs=model.inputs, outputs=xvec_layer.output))\n",
    "\n",
    "print(\"extractor:\", str(xvec_extractor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting a few embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from lidbox.visualize import plot_embedding_vector\n",
    "\n",
    "\n",
    "def is_not_copy(x):\n",
    "    return not x[\"is_copy\"]\n",
    "\n",
    "def batch_extract_embeddings(x):\n",
    "    with tf.device(\"GPU\"):\n",
    "        return dict(x, embedding=xvec_extractor(x[\"logmelspec\"]))\n",
    "\n",
    "\n",
    "embedding_demo_ds = (split2ds[\"train\"]\n",
    "                     .filter(is_not_copy)\n",
    "                     .take(12)\n",
    "                     .batch(1)\n",
    "                     .map(batch_extract_embeddings)\n",
    "                     .unbatch())\n",
    "\n",
    "for x in embedding_demo_ds.as_numpy_iterator():\n",
    "    print(x[\"id\"].decode(\"utf-8\"), x[\"embedding\"].shape)\n",
    "    plot_embedding_vector(x[\"embedding\"], figsize=(10, 0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing a language vector extractor pipeline\n",
    "\n",
    "Let's extend our existing `tf.data.Dataset` feature extraction pipelines by appending a step that extracts language vectors (embeddings) with the trained model.\n",
    "We can add all embeddings into our metadata table, under a column called `embedding` in order to keep everything neatly in one location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def ds_to_embeddings(ds):\n",
    "    to_pair = lambda x: (x[\"id\"], x[\"embedding\"])\n",
    "    ds = (ds\n",
    "        .batch(1)\n",
    "        .map(batch_extract_embeddings, num_parallel_calls=TF_AUTOTUNE)\n",
    "        .unbatch()\n",
    "        .map(to_pair, num_parallel_calls=TF_AUTOTUNE))\n",
    "\n",
    "    ids = []\n",
    "    embeddings = []\n",
    "    \n",
    "    for id, embedding in ds.as_numpy_iterator():\n",
    "        ids.append(id.decode(\"utf-8\"))\n",
    "        embeddings.append(embedding.astype(np.float32))\n",
    "        \n",
    "    df = pd.DataFrame.from_dict({\"id\": ids, \"embedding\": embeddings})\n",
    "    return df.set_index(\"id\", drop=True, verify_integrity=True)\n",
    "\n",
    "\n",
    "embeddings_by_split = (ds_to_embeddings(ds) for ds in split2ds.values())\n",
    "meta = meta.join(pd.concat(embeddings_by_split, verify_integrity=True), how=\"outer\")\n",
    "assert not meta.embedding.isna().any(axis=None), \"Missing embeddings, some rows contained NaN values\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the language vectors for back-end training\n",
    "\n",
    "Now, let's extract all embeddings and integer targets into NumPy-data and preprocess them with scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from lidbox.embed.sklearn_utils import PLDA\n",
    "\n",
    "\n",
    "def embeddings_as_numpy_data(df):\n",
    "    X = np.stack(df.embedding.values).astype(np.float32)\n",
    "    y = df.target.to_numpy(dtype=np.int32)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def random_sample(X, y, sample_size_ratio):\n",
    "    N = X.shape[0]\n",
    "    sample_size = int(sample_size_ratio*N)\n",
    "    sample_idx = np_rng.choice(np.arange(N), size=sample_size, replace=False)\n",
    "    return X[sample_idx], y[sample_idx]\n",
    "\n",
    "\n",
    "def pca_3d_scatterplot_by_label(data, targets, split_name):\n",
    "    target2lang = {t: l for l, t in lang2target.items()}\n",
    "    \n",
    "    df = pd.DataFrame.from_dict({\n",
    "        \"x\": data[:,0],\n",
    "        \"y\": data[:,1],\n",
    "        \"z\": data[:,2],\n",
    "        \"lang\": [target2lang[t] for t in targets],\n",
    "    })\n",
    "    \n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    for lang, g in df.groupby(\"lang\"):\n",
    "        ax.scatter(g.x, g.y, g.z, label=lang)\n",
    "    \n",
    "    ax.legend()\n",
    "    ax.set_title(\"3D PCA scatter plot of {} set language vectors\".format(split_name))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "train_X, train_y = embeddings_as_numpy_data(meta[meta[\"split\"]==\"train\"])\n",
    "print(\"training vectors\", train_X.shape, train_y.shape)\n",
    "test_X, test_y = embeddings_as_numpy_data(meta[meta[\"split\"]==\"test\"])\n",
    "print(\"test vectors\", test_X.shape, test_y.shape)\n",
    "\n",
    "# Standardize all vectors using training set statistics\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_X)\n",
    "train_X = scaler.transform(train_X)\n",
    "test_X = scaler.transform(test_X)\n",
    "\n",
    "# Reduce dimensions\n",
    "pre_shape = train_X.shape\n",
    "plda = PLDA()\n",
    "plda.fit(train_X, train_y)\n",
    "train_X = plda.transform(train_X)\n",
    "test_X = plda.transform(test_X)\n",
    "print(\"PLDA reduced dimensions from {} to {}\".format(pre_shape, train_X.shape))\n",
    "\n",
    "# L2-normalize vectors to surface of a unit sphere\n",
    "train_X = normalize(train_X)\n",
    "test_X = normalize(test_X)\n",
    "\n",
    "# Map vectors to 3D with PCA and plot scatterplots of 10% random samples\n",
    "pca = PCA(n_components=3, whiten=False)\n",
    "pca.fit(train_X)\n",
    "\n",
    "X, y = random_sample(pca.transform(train_X), train_y, 0.1)\n",
    "pca_3d_scatterplot_by_label(X, y, \"training\")\n",
    "\n",
    "X, y = random_sample(pca.transform(test_X), test_y, 0.1)\n",
    "pca_3d_scatterplot_by_label(X, y, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit classifier on training set vectors and evaluate on test set vectors\n",
    "\n",
    "Finally, we train a classifier on the training set vectors and predict some language scores on the test set vectors, from which we compute all metrics as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from lidbox.util import classification_report\n",
    "\n",
    "\n",
    "# Fit classifier\n",
    "clf = GaussianNB()\n",
    "clf.fit(train_X, train_y)\n",
    "\n",
    "# Predict scores on test set with classifier and compute metrics\n",
    "test_pred = clf.predict_log_proba(test_X)\n",
    "# Clamp -infs to -100\n",
    "test_pred = np.maximum(-100, test_pred)\n",
    "report = classification_report(test_y, test_pred, lang2target)\n",
    "display_classification_report(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "We were unable to improve our classification results by training a separate back-end classifier on the internal representation of the x-vector neural network.\n",
    "However, this technique can be useful if you have a pre-trained neural network and want to train a classifier on new data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
